{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Data\n",
    "In this section, we load the census tract shapefile and air quality monitor CSV data. \n",
    "We then convert the monitor CSV to a GeoDataFrame and check that both datasets are loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scripts'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mosmnx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mox\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnetworkx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnx\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscripts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_census_tracts, load_monitors\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m     34\u001b[39m warnings.filterwarnings(\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m, message=\u001b[33m\"\u001b[39m\u001b[33mThe weights matrix is not fully connected\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'scripts'"
     ]
    }
   ],
   "source": [
    "# Core numerical and data manipulation libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "from kneed import KneeLocator\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import folium\n",
    "\n",
    "# Geospatial libraries\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString\n",
    "\n",
    "# Machine learning for spatial clustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "# Spatial statistical analysis\n",
    "import libpysal\n",
    "from esda import Moran, Moran_Local\n",
    "\n",
    "# Network analysis and OSM data\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "\n",
    "from scripts.data_loader import load_census_tracts, load_monitors\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"The weights matrix is not fully connected\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"The weights matrix is not symmetric\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"The weights matrix is not square\")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "# Set the plotting style\n",
    "sns.set_style('whitegrid')\n",
    "# Set the color palette\n",
    "sns.set_palette('deep')\n",
    "# Set the figure size for plots\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "# Set the font size for plots\n",
    "plt.rcParams['font.size'] = 12\n",
    "# Set the color palette for plots\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=sns.color_palette())\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['axes.edgecolor'] = 'black'\n",
    "plt.rcParams['axes.linewidth'] = 1.5\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['axes.titlesize'] = 'large'\n",
    "plt.rcParams['axes.labelsize'] = 'large'\n",
    "# plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.labelcolor'] = 'black'\n",
    "plt.rcParams['axes.titlecolor'] = 'black'\n",
    "plt.rcParams['axes.titleweight'] = 'bold'\n",
    "plt.rcParams['axes.titlepad'] = 10\n",
    "\n",
    "# Load Census Tract shapefile\n",
    "tracts_gdf = load_census_tracts(\"data/tl_2024_06_tract.zip\")\n",
    "\n",
    "# Load Air Quality Monitor CSV\n",
    "monitors_gdf = load_monitors(\"data/annual_conc_by_monitor_2024.csv\")\n",
    "\n",
    "# Create GeoDataFrame for monitors, using Longitude and Latitude columns\n",
    "monitors_gdf = gpd.GeoDataFrame(\n",
    "    monitors_df, \n",
    "    geometry=gpd.points_from_xy(monitors_df['Longitude'], monitors_df['Latitude']),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Add a unique identifier for monitors if not present\n",
    "monitors_gdf.reset_index(inplace=True)\n",
    "monitors_gdf.rename(columns={'index': 'monitor_id'}, inplace=True)\n",
    "\n",
    "print(\"Shape of tracts:\", tracts.shape)\n",
    "print(\"Shape of monitors:\", monitors_gdf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Inspection: Geometry Complexity and Area Statistics\n",
    "We inspect the census tract dataset to determine:\n",
    "- Total number of features\n",
    "- Geometry complexity (number of vertices per feature)\n",
    "- Area statistics (min, max, average area in square kilometers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print high-level info about the GeoDataFrames\n",
    "print(\"TRACTS INFO:\")\n",
    "tracts.info()\n",
    "print(\"\\nMONITORS INFO:\")\n",
    "monitors_gdf.info()\n",
    "\n",
    "# Peek at a few rows\n",
    "print(\"\\nTRACTS HEAD:\")\n",
    "display(tracts.head(3))\n",
    "print(\"\\nMONITORS HEAD:\")\n",
    "display(monitors_gdf.head(3))\n",
    "\n",
    "# If you want descriptive stats for numeric columns:\n",
    "print(\"\\nDescriptive Stats for MONITORS:\")\n",
    "display(monitors_gdf.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values in each column\n",
    "print(\"Missing values in tracts:\")\n",
    "print(tracts.isna().sum())\n",
    "\n",
    "print(\"\\nMissing values in monitors_gdf:\")\n",
    "print(monitors_gdf.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pollutant Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pollutant = \"Ozone\"  # or \"PM2.5 - Local Conditions\"\n",
    "subset = monitors_gdf[monitors_gdf[\"Parameter Name\"] == target_pollutant]\n",
    "print(f\"\\nNumber of rows for {target_pollutant}:\", len(subset))\n",
    "display(subset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=subset, x=\"Arithmetic Mean\", kde=True)\n",
    "plt.title(f\"Distribution of {target_pollutant} Arithmetic Mean\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinate Reference Systems (CRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tracts to EPSG:4326 (WGS84) for consistency in some operations\n",
    "tracts_filtered_wgs = tracts.to_crs(epsg=4326)\n",
    "\n",
    "# 1. Number of features\n",
    "num_features = len(tracts_filtered_wgs)\n",
    "print(\"Number of features in tracts_filtered_wgs:\", num_features)\n",
    "\n",
    "# 2. Geometry Complexity\n",
    "def count_vertices(geom):\n",
    "    \"\"\"Count number of vertices in a geometry (for Polygon or MultiPolygon).\"\"\"\n",
    "    if geom.geom_type == 'Polygon':\n",
    "        return len(geom.exterior.coords)\n",
    "    elif geom.geom_type == 'MultiPolygon':\n",
    "        return sum(len(part.exterior.coords) for part in geom.geoms)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "tracts_filtered_wgs['num_vertices'] = tracts_filtered_wgs.geometry.apply(count_vertices)\n",
    "avg_vertices = tracts_filtered_wgs['num_vertices'].mean()\n",
    "min_vertices = tracts_filtered_wgs['num_vertices'].min()\n",
    "max_vertices = tracts_filtered_wgs['num_vertices'].max()\n",
    "print(\"\\nGeometry Complexity (vertices per feature):\")\n",
    "print(f\" - Average vertices: {avg_vertices:.2f}\")\n",
    "print(f\" - Minimum vertices: {min_vertices}\")\n",
    "print(f\" - Maximum vertices: {max_vertices}\")\n",
    "\n",
    "# 3. Area Statistics\n",
    "# Reproject tracts to EPSG:3310 (California Albers Equal Area) for accurate area calculation\n",
    "tracts_proj = tracts.to_crs(epsg=3310)\n",
    "tracts_filtered_wgs['area_sq_km'] = tracts_proj.geometry.area / 1e6  # area in sq km\n",
    "\n",
    "min_area = tracts_filtered_wgs['area_sq_km'].min()\n",
    "max_area = tracts_filtered_wgs['area_sq_km'].max()\n",
    "avg_area = tracts_filtered_wgs['area_sq_km'].mean()\n",
    "print(\"\\nCensus Tract Area (sq km) Statistics:\")\n",
    "print(f\" - Minimum area: {min_area:.2f} sq km\")\n",
    "print(f\" - Maximum area: {max_area:.2f} sq km\")\n",
    "print(f\" - Average area: {avg_area:.2f} sq km\")\n",
    "\n",
    "print(\"\\nMonitors CRS:\", monitors_gdf.crs)\n",
    "print(\"tracts_filtered_wgs CRS:\", tracts_filtered_wgs.crs)\n",
    "\n",
    "# Inspect a few rows of each dataset\n",
    "print(\"Number of census tracts loaded:\", len(tracts))\n",
    "print(\"Number of monitors loaded:\", len(monitors_gdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invalid Geometry or Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows with missing geometry in monitors\n",
    "monitors_gdf = monitors_gdf[monitors_gdf.geometry.notna()].copy()\n",
    "\n",
    "# Drop duplicates if needed (e.g., duplicates in monitor ID + geometry)\n",
    "monitors_gdf.drop_duplicates(subset=[\"monitor_id\", \"Latitude\", \"Longitude\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out-of-Range Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_valid_coords = (\n",
    "    (monitors_gdf.geometry.y >= -90) & (monitors_gdf.geometry.y <= 90) &\n",
    "    (monitors_gdf.geometry.x >= -180) & (monitors_gdf.geometry.x <= 180)\n",
    ")\n",
    "monitors_gdf = monitors_gdf[mask_valid_coords].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Selection and Renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Keep only certain columns\n",
    "cols_to_keep = [\n",
    "    \"monitor_id\", \"State Code\", \"County Code\", \"Site Num\", \"Parameter Name\",\n",
    "    \"Year\", \"Units of Measure\", \"Arithmetic Mean\", \"Latitude\", \"Longitude\",\n",
    "    \"geometry\"\n",
    "]\n",
    "monitors_gdf = monitors_gdf[cols_to_keep].copy()\n",
    "\n",
    "# Optional: Rename columns for clarity\n",
    "monitors_gdf.rename(columns={\n",
    "    \"Arithmetic Mean\": \"value_mean\",\n",
    "    \"Parameter Name\": \"pollutant_name\"\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pollutant-Specific Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for Ozone monitors\n",
    "ozone_gdf = monitors_gdf[monitors_gdf[\"pollutant_name\"] == \"Ozone\"].copy()\n",
    "ozone_gdf.info()\n",
    "\n",
    "# If you want a certain year or range of years, filter further\n",
    "ozone_gdf = ozone_gdf[ozone_gdf[\"Year\"] == 2024]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing or Zero Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop or fill missing values\n",
    "ozone_gdf = ozone_gdf[ozone_gdf[\"value_mean\"].notna()].copy()\n",
    "\n",
    "# If you suspect zeros are invalid, filter them out:\n",
    "ozero_mask = ozone_gdf[\"value_mean\"] > 0.0\n",
    "ozone_gdf = ozone_gdf[ozero_mask].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove top/bottom 1% of values\n",
    "low_cut = ozone_gdf[\"value_mean\"].quantile(0.01)\n",
    "high_cut = ozone_gdf[\"value_mean\"].quantile(0.99)\n",
    "mask_outliers = (ozone_gdf[\"value_mean\"] >= low_cut) & (ozone_gdf[\"value_mean\"] <= high_cut)\n",
    "ozone_gdf = ozone_gdf[mask_outliers].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box-Cox transform\n",
    "ozone_boxcox, lambda_ = boxcox(ozone_gdf[\"value_mean\"])\n",
    "ozone_gdf[\"value_boxcox\"] = ozone_boxcox\n",
    "print(\"Box-Cox lambda:\", lambda_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Join & Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we integrate the air quality monitor data with census tract polygons and visualize the spatial distribution of pollution. We will:\n",
    "- Spatially join air quality monitor points to their containing census tracts.\n",
    "- Aggregate pollutant metrics per tract, using ozone (O₃).\n",
    "- Visualize the data with a static choropleth map (using Matplotlib) and an interactive map (using Folium), and save the interactive map as an HTML file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Join of Monitors to Census Tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure both GeoDataFrames have the same CRS (project if necessary)\n",
    "# Make sure 'ozone_gdf' uses the same CRS as 'tracts'\n",
    "ozone_gdf = ozone_gdf.to_crs(tracts.crs)\n",
    "\n",
    "# Perform spatial join: assign each monitor the attributes of the tract it falls in\n",
    "# Spatially join the Ozone monitors to census tracts\n",
    "ozone_in_tracts = gpd.sjoin(\n",
    "    ozone_gdf,      # your preprocessed Ozone data\n",
    "    tracts,         # the census tract polygons\n",
    "    how='inner',    # only keep monitors that fall inside a tract\n",
    "    predicate='intersects'\n",
    ")\n",
    "\n",
    "print(f\"Joined Ozone records: {len(ozone_in_tracts)}\")\n",
    "display(ozone_in_tracts.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating Pollutant Metrics per Tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = ozone_in_tracts.groupby('GEOID')['value_mean'].mean().reset_index()\n",
    "\n",
    "# Rename the aggregated column to 'Ozone' for clarity\n",
    "grouped.rename(columns={'value_mean': 'Ozone'}, inplace=True)\n",
    "\n",
    "print(\"Aggregated Ozone data (first few rows):\")\n",
    "display(grouped.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of tracts for clarity\n",
    "tracts_ozone = tracts.copy()\n",
    "\n",
    "# Merge on the 'GEOID' column\n",
    "tracts_ozone = tracts_ozone.merge(grouped, on='GEOID', how='left')\n",
    "\n",
    "# Check how many tracts got Ozone data\n",
    "num_ozone = tracts_ozone['Ozone'].notna().sum()\n",
    "print(f\"Tracts with Ozone data: {num_ozone} / {len(tracts_ozone)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static Map of Pollutant Levels by Tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'tracts_ozone' is in EPSG:4326 if you want lat/lon plotting\n",
    "tracts_ozone = tracts_ozone.to_crs(epsg=4326)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Plot tracts colored by 'Ozone' column\n",
    "tracts_ozone.plot(\n",
    "    column='Ozone',\n",
    "    cmap='OrRd',\n",
    "    legend=True,\n",
    "    ax=ax,\n",
    "    edgecolor='black',\n",
    "    linewidth=0.5,\n",
    "    alpha=0.8,\n",
    "    missing_kwds={\n",
    "        \"color\": \"lightgrey\",\n",
    "        \"edgecolor\": \"black\",\n",
    "        \"hatch\": \"\",\n",
    "        \"label\": \"No Data\"\n",
    "    }\n",
    ")\n",
    "\n",
    "ax.set_title(\"Census Tracts by Mean Ozone Concentration\", fontsize=14)\n",
    "ax.set_xlabel(\"Longitude\", fontsize=12)\n",
    "ax.set_ylabel(\"Latitude\", fontsize=12)\n",
    "\n",
    "# Force the axes to show the full extent of the data\n",
    "minx, miny, maxx, maxy = tracts_ozone.total_bounds\n",
    "ax.set_xlim(minx, maxx)\n",
    "ax.set_ylim(miny, maxy)\n",
    "\n",
    "# Create a custom legend entry for missing data\n",
    "missing_patch = mpatches.Patch(facecolor=\"lightgrey\", edgecolor=\"black\", label=\"No Data\")\n",
    "ax.legend(handles=[missing_patch], loc='lower left', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Map with Folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Center the map roughly over California\n",
    "m = folium.Map(location=[36.77, -119.42], zoom_start=6)\n",
    "\n",
    "# Convert 'tracts_ozone' to GeoJSON for Folium\n",
    "# We'll drop rows with no geometry or Ozone for clarity\n",
    "tracts_for_folium = tracts_ozone.dropna(subset=['Ozone', 'geometry']).copy()\n",
    "\n",
    "# Add the choropleth\n",
    "folium.Choropleth(\n",
    "    geo_data=tracts_for_folium,\n",
    "    name=\"Ozone\",\n",
    "    data=tracts_for_folium,\n",
    "    columns=[\"GEOID\", \"Ozone\"],\n",
    "    key_on=\"feature.properties.GEOID\",\n",
    "    fill_color=\"YlOrRd\",\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    legend_name=\"Mean Ozone Concentration\"\n",
    ").add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "m.save(\"maps/ozone_map.html\")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Clustering of Air Quality Monitors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the Optimal Epsilon (ε) with k-Distance Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Ensure both Ozone data and tracts share the same CRS\n",
    "ozone_gdf = ozone_gdf.to_crs(tracts.crs)\n",
    "\n",
    "# 2) Spatially join Ozone monitors with census tracts\n",
    "ozone_in_tracts = gpd.sjoin(\n",
    "    ozone_gdf, \n",
    "    tracts, \n",
    "    how='inner', \n",
    "    predicate='intersects'\n",
    ")\n",
    "\n",
    "print(f\"Number of Ozone monitors after join: {len(ozone_in_tracts)}\")\n",
    "display(ozone_in_tracts.head(3))\n",
    "\n",
    "# Option A: Use the original 'value_mean' for Ozone\n",
    "# ozone_in_tracts['Ozone'] = ozone_in_tracts['value_mean']\n",
    "\n",
    "# Option B: Use your log transform or Box-Cox transform instead\n",
    "# ozone_in_tracts['Ozone'] = ozone_in_tracts['value_log']\n",
    "ozone_in_tracts['Ozone'] = ozone_in_tracts['value_boxcox']\n",
    "\n",
    "# Drop any rows with missing Ozone\n",
    "ozone_in_tracts = ozone_in_tracts[ozone_in_tracts['Ozone'].notna()].copy()\n",
    "\n",
    "# Extract coordinate arrays (make sure the geometry is still in a projected or lat/lon CRS)\n",
    "coords = np.array(list(zip(ozone_in_tracts.geometry.x, ozone_in_tracts.geometry.y)))\n",
    "\n",
    "# Combine coordinates + Ozone values into a single feature matrix X\n",
    "ozone_vals = ozone_in_tracts['Ozone'].values\n",
    "X = np.column_stack([coords, ozone_vals])\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "\n",
    "k = 5  # If min_samples=6, then k=5 for the k-distance\n",
    "nbrs = NearestNeighbors(n_neighbors=k).fit(X)\n",
    "distances, indices = nbrs.kneighbors(X)\n",
    "kth_distances = np.sort(distances[:, k-1])\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(kth_distances)\n",
    "plt.title(f\"{k}-distance graph for DBSCAN\")\n",
    "plt.xlabel(\"Point (sorted by distance to 5th neighbor)\")\n",
    "plt.ylabel(f\"Distance to {k}th nearest neighbor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying DBSCAN Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose epsilon based on the k-distance elbow, e.g., eps=0.5\n",
    "eps_opt = 0.52\n",
    "min_pts = 6\n",
    "\n",
    "db = DBSCAN(eps=eps_opt, min_samples=min_pts)\n",
    "labels = db.fit_predict(X)\n",
    "\n",
    "ozone_in_tracts['cluster'] = labels\n",
    "num_clusters = len(set(labels) - {-1})\n",
    "noise_points = list(labels).count(-1)\n",
    "\n",
    "print(f\"DBSCAN identified {num_clusters} clusters\")\n",
    "print(f\"Noise points (outliers): {noise_points}\")\n",
    "\n",
    "cluster_counts = pd.Series(labels).value_counts().sort_index()\n",
    "print(\"Cluster sizes:\", cluster_counts.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping the Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a map center (e.g., approximate center of California)\n",
    "latitude_center = 36.77  \n",
    "longitude_center = -119.42\n",
    "\n",
    "m_clusters = folium.Map(location=[latitude_center, longitude_center], zoom_start=6)\n",
    "\n",
    "# (Optional) Add tract boundaries in light gray\n",
    "folium.GeoJson(\n",
    "    tracts.to_crs(epsg=4326).geometry,  # ensure tracts are in lat/lon\n",
    "    name=\"Tracts\",\n",
    "    style_function=lambda x: {'fillColor': 'transparent', 'color': 'black', 'weight': 0.5}\n",
    ").add_to(m_clusters)\n",
    "\n",
    "# Define colors for clusters\n",
    "num_clusters = len(set(labels) - {-1})\n",
    "colormap = cm.get_cmap('tab10', num_clusters)  # discrete colormap\n",
    "cluster_colors = {\n",
    "    i: f\"#{int(colormap(i)[0]*255):02x}{int(colormap(i)[1]*255):02x}{int(colormap(i)[2]*255):02x}\"\n",
    "    for i in range(num_clusters)\n",
    "}\n",
    "# Noise color\n",
    "cluster_colors[-1] = \"gray\"\n",
    "\n",
    "# Add monitor points to the map\n",
    "for idx, row in ozone_in_tracts.iterrows():\n",
    "    cl = row['cluster']\n",
    "    color = cluster_colors.get(cl, \"gray\")\n",
    "    # For the popup, we show the cluster label and Ozone concentration\n",
    "    popup_text = (\n",
    "        f\"Monitor ID: {row['monitor_id']}<br>\"\n",
    "        f\"Cluster: {cl}<br>\"\n",
    "        f\"Ozone: {row['Ozone']:.4f}\"\n",
    "    )\n",
    "    folium.CircleMarker(\n",
    "        location=[row.geometry.y, row.geometry.x],\n",
    "        radius=5,\n",
    "        color=color,\n",
    "        fill=True,\n",
    "        fill_opacity=0.8,\n",
    "        popup=popup_text\n",
    "    ).add_to(m_clusters)\n",
    "\n",
    "folium.LayerControl().add_to(m_clusters)\n",
    "\n",
    "# Save or display\n",
    "m_clusters.save(\"maps/ozone_clusters_map.html\")\n",
    "m_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Autocorrelation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Ozone Monitors to Tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 1) Ensure 'ozone_gdf' (preprocessed Ozone monitors) and 'tracts' share the same CRS\n",
    "# ------------------------------------------------------------------------------\n",
    "ozone_gdf = ozone_gdf.to_crs(tracts.crs)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2) Spatial join: attach tract info to each Ozone monitor\n",
    "# ------------------------------------------------------------------------------\n",
    "ozone_in_tracts = gpd.sjoin(\n",
    "    ozone_gdf,    # preprocessed Ozone monitors\n",
    "    tracts,       # census tracts\n",
    "    how='inner',\n",
    "    predicate='intersects'\n",
    ")\n",
    "\n",
    "print(f\"Joined Ozone records: {len(ozone_in_tracts)}\")\n",
    "display(ozone_in_tracts.head(3))\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3) Aggregate Ozone by tract (mean Ozone per GEOID)\n",
    "# ------------------------------------------------------------------------------\n",
    "grouped = ozone_in_tracts.groupby('GEOID')['value_mean'].mean().reset_index()\n",
    "grouped.rename(columns={'value_mean': 'Ozone'}, inplace=True)\n",
    "\n",
    "print(\"Aggregated Ozone data (first few rows):\")\n",
    "display(grouped.head(5))\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4) Merge aggregated Ozone data back to the census tracts\n",
    "# ------------------------------------------------------------------------------\n",
    "tracts_gdf = tracts.copy()  # keep original tracts safe\n",
    "tracts_gdf = tracts_gdf.merge(grouped, on='GEOID', how='left')\n",
    "\n",
    "# Print stats about the Ozone column\n",
    "num_ozone = tracts_gdf['Ozone'].notna().sum()\n",
    "print(f\"Tracts with Ozone data: {num_ozone} / {len(tracts_gdf)}\")\n",
    "print(\"Min Ozone:\", tracts_gdf['Ozone'].min(skipna=True))\n",
    "print(\"Max Ozone:\", tracts_gdf['Ozone'].max(skipna=True))\n",
    "print(\"Mean Ozone:\", tracts_gdf['Ozone'].mean(skipna=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Spatial Weights & Remove Islands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 5) Construct spatial weights (Queen contiguity) & row-standardize\n",
    "# ------------------------------------------------------------------------------\n",
    "w = libpysal.weights.Queen.from_dataframe(tracts_gdf, use_index=False)\n",
    "w.transform = 'R'\n",
    "\n",
    "# Identify islands (tracts with no neighbors) and remove them\n",
    "islands = w.islands\n",
    "if islands:\n",
    "    print(\"Removing island tracts with indices:\", islands)\n",
    "    tracts_gdf = tracts_gdf.drop(index=islands).copy()\n",
    "    # Recompute weights on the filtered data\n",
    "    w = libpysal.weights.Queen.from_dataframe(tracts_gdf, use_index=False)\n",
    "    w.transform = 'R'\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 6) Check connected components\n",
    "# ------------------------------------------------------------------------------\n",
    "components = w.component_labels\n",
    "component_counts = collections.Counter(components)\n",
    "print(\"Component counts:\", component_counts)\n",
    "\n",
    "# Identify the largest connected component\n",
    "largest_component = component_counts.most_common(1)[0][0]\n",
    "print(\"Largest component label:\", largest_component)\n",
    "\n",
    "# Create a mask for tracts belonging to the largest component\n",
    "mask = np.array(components) == largest_component\n",
    "tracts_gdf_largest = tracts_gdf.iloc[mask].copy()\n",
    "\n",
    "# Recompute spatial weights for the largest component\n",
    "w = libpysal.weights.Queen.from_dataframe(tracts_gdf_largest, use_index=False)\n",
    "w.transform = 'R'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Moran’s I for Ozone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 7) Extract Ozone values & compute Global Moran's I\n",
    "# ------------------------------------------------------------------------------\n",
    "y = tracts_gdf_largest['Ozone'].values\n",
    "\n",
    "print(\"After filtering to the largest component:\")\n",
    "print(\"Min Ozone:\", np.nanmin(y))\n",
    "print(\"Max Ozone:\", np.nanmax(y))\n",
    "print(\"Mean Ozone:\", np.nanmean(y))\n",
    "\n",
    "moran = Moran(y, w)\n",
    "print(f\"Global Moran's I: {moran.I:.3f}\")\n",
    "print(f\"P-value: {moran.p_sim:.3f} (two-sided)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Moran’s I (LISA) and Cluster Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 8) Local Moran's I\n",
    "# ------------------------------------------------------------------------------\n",
    "lisa = Moran_Local(y, w)\n",
    "\n",
    "local_I = lisa.Is     # local Moran's I values\n",
    "p_vals = lisa.p_sim   # p-values for each local I\n",
    "signif = p_vals < 0.05  # significance at 95%\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 9) Classify each tract by cluster type\n",
    "# ------------------------------------------------------------------------------\n",
    "clusters = []\n",
    "for i, val in enumerate(y):\n",
    "    if not signif[i]:\n",
    "        clusters.append('Not significant')\n",
    "    else:\n",
    "        # Compare value and its spatial lag\n",
    "        if val > y.mean() and lisa.y_z[i] > 0:\n",
    "            clusters.append('High-High')\n",
    "        elif val < y.mean() and lisa.y_z[i] < 0:\n",
    "            clusters.append('Low-Low')\n",
    "        elif val > y.mean() and lisa.y_z[i] < 0:\n",
    "            clusters.append('High-Low')\n",
    "        elif val < y.mean() and lisa.y_z[i] > 0:\n",
    "            clusters.append('Low-High')\n",
    "        else:\n",
    "            clusters.append('Not significant')\n",
    "\n",
    "tracts_gdf_largest['LISA_cluster'] = clusters\n",
    "\n",
    "print(\"Local cluster counts:\")\n",
    "print(pd.Series(clusters).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LISA Cluster Significance Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 10) Plot the LISA cluster map\n",
    "# ------------------------------------------------------------------------------\n",
    "tracts_proj = tracts_gdf_largest.to_crs(epsg=3857)\n",
    "\n",
    "color_map = {\n",
    "    'High-High': 'red',\n",
    "    'Low-Low': 'blue',\n",
    "    'High-Low': 'orange',\n",
    "    'Low-High': 'lightblue',\n",
    "    'Not significant': 'lightgray'\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot all tracts in light gray\n",
    "tracts_proj.plot(color='lightgray', ax=ax, edgecolor='white')\n",
    "\n",
    "# Collect handles for a custom legend\n",
    "legend_handles = []\n",
    "\n",
    "# Loop over cluster types\n",
    "for ctype, color in color_map.items():\n",
    "    if ctype == 'Not significant':\n",
    "        continue\n",
    "    subset = tracts_proj[tracts_proj['LISA_cluster'] == ctype]\n",
    "    if not subset.empty:\n",
    "        subset.plot(color=color, ax=ax, edgecolor='white', label=ctype)\n",
    "        legend_handles.append(mpatches.Patch(color=color, label=ctype))\n",
    "\n",
    "# If no significant clusters, add a placeholder legend entry\n",
    "if len(legend_handles) == 0:\n",
    "    legend_handles.append(mpatches.Patch(color='lightgray', label='No significant clusters'))\n",
    "\n",
    "plt.title(\"Local Moran's I Cluster Map (Ozone)\")\n",
    "plt.legend(handles=legend_handles, loc='upper right')\n",
    "ax.set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moran Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 11) Moran Scatter Plot\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Standardize y\n",
    "y_mean = y.mean()\n",
    "y_std = y.std()\n",
    "\n",
    "if not np.isfinite(y_std) or np.isclose(y_std, 0):\n",
    "    print(\"Warning: Standard deviation is zero or non-finite. Skipping scatter plot regression.\")\n",
    "    z = np.zeros_like(y)\n",
    "    lag_z = np.zeros_like(y)\n",
    "else:\n",
    "    z = (y - y_mean) / y_std\n",
    "    w_matrix = w.full()[0]   # NxN weights matrix\n",
    "    lag = w_matrix @ y       # sum of neighbors\n",
    "    lag_z = (lag - y_mean) / y_std\n",
    "\n",
    "# Create color coding based on the LISA_cluster\n",
    "color_map_scatter = {\n",
    "    'High-High': 'red',\n",
    "    'Low-Low': 'blue',\n",
    "    'High-Low': 'orange',\n",
    "    'Low-High': 'lightblue',\n",
    "    'Not significant': 'gray'\n",
    "}\n",
    "colors = [color_map_scatter.get(c, 'gray') for c in tracts_gdf_largest['LISA_cluster']]\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(z, lag_z, c=colors, alpha=0.6)\n",
    "\n",
    "# Reference lines at 0\n",
    "plt.axhline(0, color='black', linestyle='--')\n",
    "plt.axvline(0, color='black', linestyle='--')\n",
    "\n",
    "# Optional regression line\n",
    "try:\n",
    "    m, b = np.polyfit(z, lag_z, 1)\n",
    "    plt.plot(z, m*z + b, color='green', label=\"Regression line\")\n",
    "except np.linalg.LinAlgError as e:\n",
    "    print(\"Regression line failed:\", e)\n",
    "\n",
    "plt.title(\"Moran Scatter Plot (Ozone)\")\n",
    "plt.xlabel(\"Standardized Ozone (Z)\")\n",
    "plt.ylabel(\"Standardized Spatial Lag of Ozone\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Storage and Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the census tracts with aggregated pollutant data and LISA cluster info\n",
    "# tracts_gdf.to_file(\"census_tracts_pollution.shp\")\n",
    "\n",
    "# # Save the monitors with cluster labels\n",
    "# monitors_in_tracts.to_file(\"air_quality_monitors_clusters.shp\")\n",
    "\n",
    "# # (Optional) Save any other relevant layers, e.g., a shapefile of just significant clusters\n",
    "# significant_clusters = tracts_gdf[tracts_gdf['LISA_cluster'] != 'Not significant']\n",
    "# significant_clusters.to_file(\"significant_ozone_clusters.shp\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
